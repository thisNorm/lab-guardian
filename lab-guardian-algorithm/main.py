# main.py
import logging
import sys
import time
import threading
import requests
import cv2
import numpy as np
from fastapi import FastAPI, UploadFile, File
from fastapi.responses import StreamingResponse
from fastapi.middleware.cors import CORSMiddleware

# âœ… ì»¤ìŠ¤í…€ ëª¨ë“ˆ ì„í¬íŠ¸
from ai_detector import AIDetector
from centroidtracker import CentroidTracker 
import config 

# 1. FastAPI ì•± ìƒì„±
app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

detector = AIDetector()

# ìƒíƒœ ê´€ë¦¬ ë³€ìˆ˜ë“¤
camera_streams = {} # ì˜ìƒ ë°ì´í„°
last_seen = {}      # ì˜¤í”„ë¼ì¸ ê°ì§€ìš© ì‹œê°„
trackers = {}       # âœ… ì¹´ë©”ë¼ë³„ ì¶”ì ê¸° ê´€ë¦¬ { "cam_1": CentroidTracker(), ... }

# --- [ê°•ë ¥í•œ ë¡œê·¸ ì°¨ë‹¨ ì„¤ì •] ---
logging.getLogger("uvicorn").setLevel(logging.WARNING)
logging.getLogger("uvicorn.access").setLevel(logging.WARNING)
logging.getLogger("uvicorn.error").setLevel(logging.WARNING)

def report_to_nestjs(cam_id, label):
    """
    NestJSë¡œ ì•ŒëŒì„ ë³´ëƒ…ë‹ˆë‹¤. (ì´ í•¨ìˆ˜ê°€ í˜¸ì¶œë  ë•ŒëŠ” ì´ë¯¸ 'ìƒˆë¡œìš´ ì‚¬ëŒ'ì„ì´ ê²€ì¦ëœ ìƒíƒœì…ë‹ˆë‹¤)
    """
    try:
        payload = {
            "cam_id": cam_id,
            "status": "DANGER",
            "message": f"{label} ê°ì§€! ìƒí™©ì„ í™•ì¸í•˜ì„¸ìš”."
        }
        print(f"ğŸš¨ [EVENT] {cam_id}: {label} ë°ì´í„° ì „ì†¡ (DB ì €ì¥ ìš”ì²­)") 
        # timeoutì„ ì§§ê²Œ ì£¼ì–´ ì˜ìƒ ì²˜ë¦¬ì— ë°©í•´ë˜ì§€ ì•Šê²Œ í•¨
        requests.post(f"{config.NEST_API_URL}/api/cctv/detect", json=payload, timeout=0.2)
    except:
        pass

@app.post("/upload_frame/{robot_id}")
async def upload_frame(robot_id: str, file: UploadFile = File(...)):
    try:
        contents = await file.read()
        nparr = np.frombuffer(contents, np.uint8)
        frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

        if frame is None:
            return {"status": "fail"}

        # âœ… 1. ì¥ì¹˜ ì—°ê²° ìƒíƒœ ì—…ë°ì´íŠ¸
        if robot_id not in last_seen:
            print(f"âœ… [STATUS] ì¥ì¹˜ ì—°ê²°ë¨ (ON): {robot_id}")
            # ìƒˆë¡œìš´ ì¥ì¹˜ë©´ íŠ¸ë˜ì»¤ë„ ìƒˆë¡œ ìƒì„±
            trackers[robot_id] = CentroidTracker(maxDisappeared=40)
        
        last_seen[robot_id] = time.time()
        
        # âœ… 2. AI íƒì§€ (ì¢Œí‘œ ë°›ì•„ì˜¤ê¸°)
        annotated_frame, person_rects = detector.detect_and_draw(frame)

        # âœ… 3. ì¶”ì ê¸° ì—…ë°ì´íŠ¸ (í•´ë‹¹ ë¡œë´‡ì˜ íŠ¸ë˜ì»¤ ì‚¬ìš©)
        if robot_id not in trackers:
            trackers[robot_id] = CentroidTracker(maxDisappeared=40)
            
        objects = trackers[robot_id].update(person_rects)

        # âœ… 4. ì‹ ê·œ ì¹¨ì…ì í™•ì¸ ë° ë¡œê·¸ ì „ì†¡
        # ì´ë²ˆ í”„ë ˆì„ì— 'ìƒˆë¡œ' í• ë‹¹ëœ IDê°€ ìˆëŠ”ê°€?
        if trackers[robot_id].new_detected_ids:
            for new_id in trackers[robot_id].new_detected_ids:
                msg = f"ì¹¨ì…ì (ID: {new_id})"
                report_to_nestjs(robot_id, msg) # â˜… ì—¬ê¸°ì„œë§Œ ë¡œê·¸ê°€ ì „ì†¡ë¨!

        # âœ… 5. í™”ë©´ì— ID ê·¸ë¦¬ê¸° (ì‹œê°ì  í™•ì¸ìš©)
        for (objectID, centroid) in objects.items():
            text = f"ID {objectID}"
            cv2.putText(annotated_frame, text, (centroid[0] - 10, centroid[1] - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
            cv2.circle(annotated_frame, (centroid[0], centroid[1]), 4, (0, 255, 0), -1)

        # ìŠ¤íŠ¸ë¦¼ ì—…ë°ì´íŠ¸
        camera_streams[robot_id] = annotated_frame

        return {"status": "ok"}
    except Exception as e:
        # ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ ì„œë²„ê°€ ì£½ì§€ ì•Šë„ë¡ ì²˜ë¦¬
        # print(f"Error: {e}") 
        return {"status": "error"}

@app.get("/video_feed/{cam_id}")
def video_feed(cam_id: str):
    def generate():
        try:
            print(f"ğŸ“º [STREAM] ì›¹ ëŒ€ì‹œë³´ë“œ ì†¡ì¶œ ì‹œì‘: {cam_id}")
            while True:
                if cam_id in camera_streams:
                    # JPEG ì¸ì½”ë”©
                    ret, buffer = cv2.imencode('.jpg', camera_streams[cam_id])
                    if ret:
                        yield (b'--frame\r\n'
                               b'Content-Type: image/jpeg\r\n\r\n' + buffer.tobytes() + b'\r\n')
                time.sleep(0.04) # 25 FPS ì œí•œ
        except Exception:
            print(f"ğŸ”Œ [STREAM] ì›¹ ëŒ€ì‹œë³´ë“œ ì†¡ì¶œ ì¢…ë£Œ: {cam_id}")
            pass
            
    return StreamingResponse(generate(), media_type="multipart/x-mixed-replace; boundary=frame")

# âœ… ì˜¤í”„ë¼ì¸ ê°ì§€ ìŠ¤ë ˆë“œ
def check_offline_devices():
    while True:
        current_time = time.time()
        for robot_id in list(last_seen.keys()):
            # 5ì´ˆ ì´ìƒ í†µì‹  ì—†ìœ¼ë©´ ì˜¤í”„ë¼ì¸ ì²˜ë¦¬
            if current_time - last_seen[robot_id] > 5.0:
                print(f"âŒ [STATUS] ì¥ì¹˜ ì—°ê²° ëŠê¹€ (OFF): {robot_id}")
                del last_seen[robot_id]
                if robot_id in camera_streams:
                    del camera_streams[robot_id]
                # ì—°ê²° ëŠê¸°ë©´ íŠ¸ë˜ì»¤ë„ ì‚­ì œí• ì§€, ìœ ì§€í• ì§€ ê²°ì • (ë³´í†µ ì‚­ì œ ì¶”ì²œ)
                if robot_id in trackers:
                    del trackers[robot_id]
        time.sleep(2)

threading.Thread(target=check_offline_devices, daemon=True).start()

if __name__ == "__main__":
    import uvicorn
    
    print(f"ğŸš€ ì•Œê³ ë¦¬ì¦˜ ì„œë²„ ì‹œì‘ ì¤‘... (Port: {config.PORT_ALGO})")
    
    uvicorn.run(
        app, 
        host="0.0.0.0", 
        port=config.PORT_ALGO, 
        loop="asyncio",
        access_log=False,
        log_level="warning"
    )